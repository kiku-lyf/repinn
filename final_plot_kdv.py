#!/usr/bin/env python3
"""
åŒæ—¶å¯¹æ¯”å¤šä¸ªæ¨¡å‹åœ¨KdVæ–¹ç¨‹ä¸Šçš„è¯¯å·®çƒ­å›¾
æ¯ä¸ªå­å›¾ç‹¬ç«‹é¢œè‰²æ¡ï¼Œä¸ Burgers/NS/Allen-Cahn ä»£ç ä¿æŒå®Œå…¨ä¸€è‡´
"""

import argparse
import os
import numpy as np
import torch
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
import scipy.io

from model_dict import get_model
from util import make_time_sequence

# ============ å­—ä½“å’Œæ ·å¼é…ç½® ============
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

matplotlib.rcParams.update({
    'font.family': 'serif',
    'font.serif': ['Times New Roman'],
    'font.size': 10,
    'axes.titlesize': 14,
    'axes.labelsize': 18,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
})


def build_model(model_name: str, device: str):
    """æ„å»ºæ¨¡å‹ï¼ˆä¸å…¶ä»–ä»£ç ä¿æŒä¸€è‡´ï¼‰"""
    module = get_model(type('args', (), {'model': model_name})())
    if model_name == 'KAN':
        model = module.Model(width=[2, 5, 5, 1], grid=5, k=3, grid_eps=1.0,
                             noise_scale_base=0.25, device=device).to(device)
    elif model_name == 'SetPINN':
        model = module.Model(in_dim=2, hidden_dim=32, out_dim=1, num_layer=3).to(device)
    elif model_name == 'QRes':
        model = module.Model(in_dim=2, hidden_dim=256, out_dim=1, num_layer=4).to(device)
    elif model_name == 'PINNsFormer' or model_name == 'PINNsFormer_Enc_Only':
        model = module.Model(in_dim=2, hidden_dim=32, out_dim=1, num_layer=1).to(device)
    else:
        model = module.Model(in_dim=2, hidden_dim=512, out_dim=1, num_layer=4).to(device)
    return model


def predict_in_batches(model, x_test, t_test, batch_size=1000):
    """åˆ†æ‰¹é¢„æµ‹ï¼Œé¿å… Transformer ç±»æ¨¡å‹ OOM"""
    model.eval()
    n_samples = x_test.shape[0]
    predictions = []

    with torch.no_grad():
        for i in range(0, n_samples, batch_size):
            end_idx = min(i + batch_size, n_samples)
            x_batch = x_test[i:end_idx]
            t_batch = t_test[i:end_idx]

            pred_batch = model(x_batch, t_batch)[:, 0:1]
            predictions.append(pred_batch.cpu().numpy())

            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    return np.concatenate(predictions, axis=0)


def load_kdv_data(data_path):
    """åŠ è½½ KdV æ–¹ç¨‹çš„çœŸå®è§£æ•°æ®"""
    if not os.path.exists(data_path):
        raise FileNotFoundError(f'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}')

    mat = scipy.io.loadmat(data_path)

    # æå–è§£æ•°æ®
    exact = None
    for var_name in ['usol', 'u', 'uu', 'solution']:
        if var_name in mat:
            exact = mat[var_name]
            print(f'  æ‰¾åˆ°è§£æ•°æ®å˜é‡: {var_name}')
            break

    if exact is None:
        raise ValueError(f"æ— æ³•åœ¨ {data_path} ä¸­æ‰¾åˆ°è§£æ•°æ®")

    # æå–ç½‘æ ¼ä¿¡æ¯
    x_star = None
    t_star = None

    if 'x' in mat:
        x_star = mat['x'].flatten()
    if 't' in mat:
        t_star = mat['t'].flatten()
    elif 'tt' in mat:
        t_star = mat['tt'].flatten()

    # å¦‚æœæ‰¾ä¸åˆ°ç½‘æ ¼ä¿¡æ¯ï¼Œæ ¹æ®æ•°æ®å½¢çŠ¶æ¨æ–­
    if x_star is None or t_star is None:
        if len(exact.shape) != 2:
            raise ValueError(f'è§£æ•°æ®åº”ä¸º2Dæ•°ç»„ï¼Œå®é™…å½¢çŠ¶: {exact.shape}')
        n_x, n_t = exact.shape
        x_star = np.linspace(-1, 1, n_x)
        t_star = np.linspace(0, 1, n_t)
        print(f'  è­¦å‘Š: æœªæ‰¾åˆ°ç½‘æ ¼ä¿¡æ¯ï¼Œæ ¹æ®æ•°æ®å½¢çŠ¶æ¨æ–­')

    # ç”Ÿæˆç½‘æ ¼
    TT, XX = np.meshgrid(t_star, x_star)

    # å¯¹é½æ•°æ®å½¢çŠ¶
    if exact.shape == (t_star.size, x_star.size):
        exact = exact.T
        print(f'  æ•°æ®è½¬ç½®: {(t_star.size, x_star.size)} -> {exact.shape}')
    elif exact.shape != (x_star.size, t_star.size):
        raise ValueError(f"è§£çŸ©é˜µçš„å½¢çŠ¶ä¸ç½‘æ ¼ä¸åŒ¹é…: exact={exact.shape}")

    print(f'  æ•°æ®åŠ è½½æˆåŠŸ: exact.shape={exact.shape}')
    print(f'  x: [{x_star.min():.3f}, {x_star.max():.3f}], n={len(x_star)}')
    print(f'  t: [{t_star.min():.3f}, {t_star.max():.3f}], n={len(t_star)}')

    return exact, XX, TT, x_star, t_star


def main():
    parser = argparse.ArgumentParser('Compare multiple models: KdV errors')
    parser.add_argument('--models', nargs='+', required=False,
                        default=['PINN', 'KAN', 'QRes'],
                        help='æ¨¡å‹åç§°åˆ—è¡¨')
    parser.add_argument('--model_paths', nargs='*', default=None,
                        help='æ¨¡å‹æƒé‡åˆ—è¡¨')
    parser.add_argument('--data_path', type=str, default='./kdv.mat')
    parser.add_argument('--device', type=str, default='cuda:0')
    parser.add_argument('--output_dir', type=str, default='./plots')
    parser.add_argument('--filename', type=str, default='kdv_models_errors.pdf')
    parser.add_argument('--batch_size', type=int, default=1000)

    args = parser.parse_args()
    os.makedirs(args.output_dir, exist_ok=True)

    # è¯»å–çœŸå®è§£æ•°æ®
    print(f'åŠ è½½çœŸå®è§£æ•°æ®: {args.data_path}')
    try:
        Exact, XX_ref, TT_ref, x_star, t_star = load_kdv_data(args.data_path)
    except Exception as e:
        print(f'é”™è¯¯: æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶: {str(e)}')
        import traceback
        traceback.print_exc()
        return

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    data = np.hstack([XX_ref.reshape(-1, 1), TT_ref.reshape(-1, 1)])
    print(f'  æµ‹è¯•æ•°æ®æ€»ç‚¹æ•°: {data.shape[0]}')

    models = args.models
    if args.model_paths is None or len(args.model_paths) == 0:
        model_paths = [f'./results/kdv_{m}_point.pt' for m in models]
    else:
        if len(args.model_paths) != len(models):
            raise ValueError('models ä¸ model_paths æ•°é‡ä¸ä¸€è‡´')
        model_paths = args.model_paths

    errors = []
    metrics = []

    # é€æ¨¡å‹é¢„æµ‹
    for model_name, model_path in zip(models, model_paths):
        if not os.path.exists(model_path):
            print(f'âš ï¸  è·³è¿‡ {model_name}: æ–‡ä»¶ä¸å­˜åœ¨')
            continue

        try:
            print(f'\nåŠ è½½æ¨¡å‹: {model_name}')
            model = build_model(model_name, args.device)
            state = torch.load(model_path, map_location=args.device)
            model.load_state_dict(state)

            if model_name != 'KAN':
                model.eval()

            # å‡†å¤‡æµ‹è¯•æ•°æ®
            test_data = data.copy()
            if model_name == 'PINNsFormer' or model_name == 'PINNsFormer_Enc_Only':
                test_data = make_time_sequence(test_data, num_step=5, step=1e-4)

            res_test = torch.tensor(test_data, dtype=torch.float32,
                                    requires_grad=True).to(args.device)
            x_test, t_test = res_test[:, ..., 0:1], res_test[:, ..., 1:2]

            # é¢„æµ‹
            if model_name in ['PINNsFormer', 'PINNsFormer_Enc_Only']:
                pred = predict_in_batches(model, x_test, t_test, args.batch_size)
            else:
                with torch.no_grad():
                    pred = model(x_test, t_test)[:, 0:1]
                    pred = pred.cpu().numpy()

            pred = pred.reshape(-1)
            pred_grid = pred.reshape(Exact.shape)

            # è¯¯å·®è®¡ç®—
            Exact_flat = Exact.flatten()
            err_grid = np.abs(Exact - pred_grid)
            errors.append(err_grid)

            # è®¡ç®—æŒ‡æ ‡
            rl2 = np.linalg.norm(Exact_flat - pred, 2) / np.linalg.norm(Exact_flat, 2)
            rl1 = np.mean(np.abs(Exact_flat - pred)) / np.mean(np.abs(Exact_flat))
            metrics.append((model_name, rl1, rl2))

            print(f'  âœ“ L1={rl1:.4e}, L2={rl2:.4e}')

            # é‡Šæ”¾æ˜¾å­˜
            del model, state, res_test, x_test, t_test, pred, pred_grid
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        except Exception as e:
            print(f'  âœ— {model_name} å¤±è´¥: {str(e)}')
            import traceback
            traceback.print_exc()
            continue

    if len(errors) == 0:
        print('âŒ æ²¡æœ‰æˆåŠŸçš„æ¨¡å‹')
        return

    # ============ ç»˜å›¾ï¼ˆæ¯ä¸ªå­å›¾ç‹¬ç«‹é¢œè‰²æ¡ï¼‰============
    n_models = len(errors)
    n_cols = min(3, n_models)
    n_rows = int(np.ceil(n_models / 3))

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows))
    if n_models == 1:
        axes = np.array([axes])
    axes = axes.flatten()

    print(f'\nå¸ƒå±€: {n_models}ä¸ªæ¨¡å‹ï¼Œ{n_rows} è¡Œ Ã— {n_cols} åˆ—')

    for idx, (err_grid, (model_name, rl1, rl2)) in enumerate(zip(errors, metrics)):
        ax = axes[idx]

        # ä½¿ç”¨ pcolormesh ç»˜åˆ¶çƒ­å›¾
        mesh = ax.pcolormesh(TT_ref, XX_ref, err_grid, cmap='jet',
                             shading='auto', vmin=0.0)

        # âœ… æ¯ä¸ªå­å›¾ç‹¬ç«‹é¢œè‰²æ¡
        cbar = plt.colorbar(mesh, ax=ax, fraction=0.046, pad=0.04)
        cbar.ax.tick_params(labelsize=10)

        ax.set_xlabel('$t$', fontsize=14)
        ax.set_ylabel('$x$', fontsize=14)
        ax.set_title(f'{model_name}', fontsize=14, pad=10)
        ax.tick_params(labelsize=11)

    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(n_models, len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()

    save_path = os.path.join(args.output_dir, args.filename)
    plt.savefig(save_path, dpi=600, format='pdf', bbox_inches='tight')
    plt.close(fig)

    print(f'\nâœ… å®Œæˆ! ä¿å­˜è‡³: {save_path}')
    print('\nğŸ“Š è¯¯å·®ç»Ÿè®¡ (æŒ‰ L2 æ’åº):')
    for name, rl1, rl2 in sorted(metrics, key=lambda x: x[2]):
        print(f'  {name:20s} L1={rl1:.4e}  L2={rl2:.4e}')


if __name__ == '__main__':
    main()
