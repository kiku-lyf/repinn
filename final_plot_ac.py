#!/usr/bin/env python3
"""
åŒæ—¶å¯¹æ¯”å¤šä¸ªæ¨¡å‹åœ¨Allenâ€“Cahnæ–¹ç¨‹ä¸Šçš„è¯¯å·®çƒ­å›¾
æ¯ä¸ªå­å›¾ç‹¬ç«‹é¢œè‰²æ¡ï¼Œä¸ Wave/Convection/KdV ä»£ç ä¿æŒä¸€è‡´
"""

import argparse
import os
import numpy as np
import torch
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
import scipy.io

from model_dict import get_model
from util import make_time_sequence

# ============ å­—ä½“å’Œæ ·å¼é…ç½® ============
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

matplotlib.rcParams.update({
    'font.family': 'serif',
    'font.serif': ['Times New Roman'],
    'font.size': 10,
    'axes.titlesize': 14,
    'axes.labelsize': 18,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
})


def build_model(model_name: str, device: str):
    """æ„å»ºæ¨¡å‹"""
    module = get_model(type('args', (), {'model': model_name})())
    if model_name == 'KAN':
        model = module.Model(width=[2, 5, 5, 1], grid=5, k=3, grid_eps=1.0,
                             noise_scale_base=0.25, device=device).to(device)
    elif model_name == 'SetPINN':
        model = module.Model(in_dim=2, hidden_dim=32, out_dim=1, num_layer=3).to(device)
    elif model_name == 'QRes':
        model = module.Model(in_dim=2, hidden_dim=256, out_dim=1, num_layer=4).to(device)
    elif model_name == 'PINNsFormer' or model_name == 'PINNsFormer_Enc_Only':
        model = module.Model(in_dim=2, hidden_dim=32, out_dim=1, num_layer=1).to(device)
    else:
        model = module.Model(in_dim=2, hidden_dim=512, out_dim=1, num_layer=4).to(device)
    return model


def predict_in_batches(model, x_test, t_test, batch_size=1000):
    """åˆ†æ‰¹é¢„æµ‹ï¼Œé¿å… Transformer ç±»æ¨¡å‹ OOM"""
    model.eval()
    n_samples = x_test.shape[0]
    predictions = []

    with torch.no_grad():
        for i in range(0, n_samples, batch_size):
            end_idx = min(i + batch_size, n_samples)
            x_batch = x_test[i:end_idx]
            t_batch = t_test[i:end_idx]

            pred_batch = model(x_batch, t_batch)[:, 0:1]
            predictions.append(pred_batch.cpu().numpy())

            # æ¸…ç†ç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    return np.concatenate(predictions, axis=0)


def main():
    parser = argparse.ArgumentParser('Compare multiple models: Allenâ€“Cahn errors')
    parser.add_argument('--models', nargs='+', required=False,
                        default=['PINN', 'KAN', 'QRes'],
                        help='æ¨¡å‹åç§°åˆ—è¡¨ï¼Œå¦‚: PINN KAN QRes PINNsFormer')
    parser.add_argument('--model_paths', nargs='*', default=None,
                        help='æ¨¡å‹æƒé‡åˆ—è¡¨ï¼ˆä¸modelsä¸€ä¸€å¯¹åº”ï¼‰')
    parser.add_argument('--data_path', type=str, default='./AC.mat',
                        help='Allenâ€“CahnçœŸå®è§£æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--device', type=str, default='cuda:0')
    parser.add_argument('--output_dir', type=str, default='./plots')
    parser.add_argument('--filename', type=str, default='allen_cahn_models_errors.pdf')
    parser.add_argument('--batch_size', type=int, default=1000,
                        help='PINNsFormer é¢„æµ‹æ—¶çš„æ‰¹å¤§å°')

    args = parser.parse_args()
    os.makedirs(args.output_dir, exist_ok=True)

    # è¯»å–çœŸå®è§£æ•°æ®
    print(f'åŠ è½½çœŸå®è§£æ•°æ®: {args.data_path}')
    mat = scipy.io.loadmat(args.data_path)
    Exact = mat['uu']  # shape: (nt, nx)
    t_star = mat['tt'].flatten()
    x_star = mat['x'].flatten()

    print(f'  Exact shape: {Exact.shape}')
    print(f'  x: [{x_star.min():.3f}, {x_star.max():.3f}], n={len(x_star)}')
    print(f'  t: [{t_star.min():.3f}, {t_star.max():.3f}], n={len(t_star)}')

    # ç”Ÿæˆç½‘æ ¼
    TT_ref, XX_ref = np.meshgrid(t_star, x_star)
    data = np.hstack([XX_ref.reshape(-1, 1), TT_ref.reshape(-1, 1)])

    print(f'  æµ‹è¯•æ•°æ®æ€»ç‚¹æ•°: {data.shape[0]}')

    models = args.models
    if args.model_paths is None or len(args.model_paths) == 0:
        model_paths = [f'./results/allen_cahn_{m}_point.pt' for m in models]
    else:
        if len(args.model_paths) != len(models):
            raise ValueError('models ä¸ model_paths æ•°é‡ä¸ä¸€è‡´')
        model_paths = args.model_paths

    errors = []
    metrics = []

    # é€æ¨¡å‹é¢„æµ‹
    for model_name, model_path in zip(models, model_paths):
        if not os.path.exists(model_path):
            print(f'è­¦å‘Š: æ¨¡å‹æƒé‡ä¸å­˜åœ¨: {model_path}ï¼Œè·³è¿‡')
            continue

        try:
            print(f'\nåŠ è½½æ¨¡å‹: {model_name} | {model_path}')
            model = build_model(model_name, args.device)

            print(f'  åŠ è½½æƒé‡...')
            state = torch.load(model_path, map_location=args.device)
            model.load_state_dict(state)

            if model_name != 'KAN':
                model.eval()

            # å‡†å¤‡æµ‹è¯•æ•°æ®
            print(f'  å‡†å¤‡æµ‹è¯•æ•°æ®...')
            test_data = data.copy()

            # PINNsFormer éœ€è¦æ—¶é—´åºåˆ—
            if model_name == 'PINNsFormer' or model_name == 'PINNsFormer_Enc_Only':
                print(f'  æ„é€ æ—¶é—´åºåˆ—...')
                test_data = make_time_sequence(test_data, num_step=3, step=1e-4)

            res_test = torch.tensor(test_data, dtype=torch.float32,
                                    requires_grad=True).to(args.device)
            x_test, t_test = res_test[:, ..., 0:1], res_test[:, ..., 1:2]

            print(f'  è¿›è¡Œé¢„æµ‹... (æ‰¹å¤§å°={args.batch_size})')

            # ä½¿ç”¨æ‰¹å¤„ç†é¢„æµ‹
            if model_name in ['PINNsFormer', 'PINNsFormer_Enc_Only']:
                pred = predict_in_batches(model, x_test, t_test, args.batch_size)
            else:
                with torch.no_grad():
                    pred = model(x_test, t_test)[:, 0:1]
                    pred = pred.cpu().numpy()

            pred = pred.reshape(-1)
            pred_grid = pred.reshape(XX_ref.shape)

            # è¯¯å·®è®¡ç®—
            Exact_flat = Exact.flatten()
            err_grid = np.abs(Exact - pred_grid)
            errors.append(err_grid)

            # è®¡ç®—æŒ‡æ ‡ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
            rl2 = np.linalg.norm(Exact_flat - pred, 2) / np.linalg.norm(Exact_flat, 2)
            rl1 = np.mean(np.abs(Exact_flat - pred)) / np.mean(np.abs(Exact_flat))
            metrics.append((model_name, rl1, rl2))

            print(f'  âœ“ {model_name} å®Œæˆ: L1={rl1:.4e}, L2={rl2:.4e}')

            # é‡Šæ”¾æ˜¾å­˜
            del model, state, res_test, x_test, t_test, pred, pred_grid
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        except Exception as e:
            print(f'  âœ— {model_name} å¤„ç†å¤±è´¥: {str(e)}')
            import traceback
            traceback.print_exc()
            continue

    if len(errors) == 0:
        print('æ— å¯ç”¨æ¨¡å‹ï¼Œç»“æŸã€‚')
        return

    # ============ ç»˜å›¾ï¼šæ¯ä¸ªå­å›¾ç‹¬ç«‹é¢œè‰²æ¡ ============
    n_models = len(errors)
    n_cols = min(3, n_models)  # æ¯è¡Œæœ€å¤š3åˆ—
    n_rows = int(np.ceil(n_models / 3))  # è®¡ç®—éœ€è¦çš„è¡Œæ•°

    # ä½¿ç”¨ subplots åˆ›å»ºå­å›¾æ•°ç»„
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows))

    # å¤„ç†å•ä¸ªå­å›¾çš„æƒ…å†µ
    if n_models == 1:
        axes = np.array([axes])
    axes = axes.flatten()

    print(f'\nå¸ƒå±€ä¿¡æ¯: {n_models}ä¸ªæ¨¡å‹ï¼Œæ’åˆ—ä¸º {n_rows} è¡Œ Ã— {n_cols} åˆ—')

    # é€æ¨¡å‹ç»˜åˆ¶è¯¯å·®çƒ­å›¾ï¼ˆæ¯ä¸ªå­å›¾ç‹¬ç«‹é¢œè‰²æ¡ï¼‰
    for idx, (err_grid, (model_name, rl1, rl2)) in enumerate(zip(errors, metrics)):
        ax = axes[idx]

        # âœ… åˆ é™¤ vmax å‚æ•°ï¼Œè®©æ¯ä¸ªå­å›¾è‡ªåŠ¨ç¼©æ”¾
        mesh = ax.pcolormesh(TT_ref, XX_ref, err_grid, cmap='jet',
                             shading='auto', vmin=0.0)

        # âœ… ä¸ºæ¯ä¸ªå­å›¾åˆ›å»ºç‹¬ç«‹çš„é¢œè‰²æ¡
        cbar = plt.colorbar(mesh, ax=ax, fraction=0.046, pad=0.04)
        cbar.ax.tick_params(labelsize=10)

        # ä½¿ç”¨æ•°å­¦æ–‡æœ¬æ ¼å¼çš„æ–œä½“å˜é‡
        ax.set_xlabel('$t$', fontsize=14)
        ax.set_ylabel('$x$', fontsize=14)

        # æ ‡é¢˜åªæ˜¾ç¤ºæ¨¡å‹åç§°
        ax.set_title(f'{model_name}', fontsize=14, pad=10)
        ax.tick_params(labelsize=11)

    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(n_models, len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    save_path = os.path.join(args.output_dir, args.filename)
    plt.savefig(save_path, dpi=600, format='pdf', bbox_inches='tight')
    plt.close(fig)

    print(f'\nâœ… å®Œæˆ! è¯¯å·®å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}')
    print('\nğŸ“Š è¯¯å·®ç»Ÿè®¡ (æŒ‰ L2 æ’åº):')
    for name, rl1, rl2 in sorted(metrics, key=lambda x: x[2]):
        print(f'  {name:20s} L1={rl1:.4e}  L2={rl2:.4e}')


if __name__ == '__main__':
    main()
